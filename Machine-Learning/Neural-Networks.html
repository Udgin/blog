<title>Neural Networks</title><meta name=viewport content="width=device-width, initial-scale=1.0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.4/css/bulma.min.css><style>.content .tag,.content .number{display:inline;padding:inherit;font-size:inherit;line-height:inherit;text-align:inherit;vertical-align:inherit;border-radius:inherit;font-weight:inherit;white-space:inherit;background:inherit;margin:inherit}</style><nav class=navbar role=navigation aria-label="main navigation"><div class=navbar-brand><a class=navbar-item href=..\index.html><img src=..\favicon.ico width=28 height=28>Â Programming notes</a> <a role=button class="navbar-burger burger" aria-label=menu aria-expanded=false data-target=navbarBasicExample><span aria-hidden></span> <span aria-hidden></span> <span aria-hidden></span></a></div><div id=navbarBasicExample class=navbar-menu><div class=navbar-start><div class=navbar-item><div class="navbar-item has-dropdown is-hoverable"><a class=navbar-link>About me</a><div class=navbar-dropdown> <a class=navbar-item>Facebook</a> <a class=navbar-item>LinkedIn</a> <a class=navbar-item>GitHub</a> <a class=navbar-item>Email</a></div></div></div></div></div></nav><section class=section><div class=container><div class=content><h1 id=neural-networks>Neural Networks</h1><p>Neural networks are limited imitations of how our own brains work. They've had a big recent resurgence because of advances in computer hardware.<p>In neural networks, we use the same logistic function as in classification: <span class=math>\(\frac{1}{1 + e^{-\theta^Tx}}\)</span>. In neural networks however we sometimes call it a sigmoid (logistic) activation function.<p>Visually, a simplistic representation looks like:<p><span class=math>\[\begin{bmatrix}x_0 \newline x_1 \newline x_2 \newline x_3\end{bmatrix}\rightarrow\begin{bmatrix}a_1^{(2)} \newline a_2^{(2)} \newline a_3^{(2)} \newline \end{bmatrix}\rightarrow h_\theta(x)\]</span><p>The values for each of the "activation" nodes is obtained as follows:<p><span class=math>\[\begin{align*} a_1^{(2)} = g(\Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_1 + \Theta_{12}^{(1)}x_2 + \Theta_{13}^{(1)}x_3) \newline a_2^{(2)} = g(\Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_1 + \Theta_{22}^{(1)}x_2 + \Theta_{23}^{(1)}x_3) \newline a_3^{(2)} = g(\Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_1 + \Theta_{32}^{(1)}x_2 + \Theta_{33}^{(1)}x_3) \newline h_\Theta(x) = a_1^{(3)} = g(\Theta_{10}^{(2)}a_0^{(2)} + \Theta_{11}^{(2)}a_1^{(2)} + \Theta_{12}^{(2)}a_2^{(2)} + \Theta_{13}^{(2)}a_3^{(2)}) \newline \end{align*}\]</span><p>Each layer gets its own matrix of weights, <span class=math>\(\Theta^{(j)}\)</span>.<p>The dimensions of these matrices of weights is determined as follows:<p><span class=math>\[\text{If network has $s_j$ units in layer $j$ and $s_{j+1}$ units in layer $j+1$, then $\Theta^{(j)}$ will be of dimension $s_{j+1} \times (s_j + 1)$.}\]</span><h3 id=multiclass-classification>Multiclass Classification</h3><p><span class=math>\[\begin{align*}\begin{bmatrix}x_0 \newline x_1 \newline x_2 \newline\cdots \newline x_n\end{bmatrix} \rightarrow\begin{bmatrix}a_0^{(2)} \newline a_1^{(2)} \newline a_2^{(2)} \newline\cdots\end{bmatrix} \rightarrow\begin{bmatrix}a_0^{(3)} \newline a_1^{(3)} \newline a_2^{(3)} \newline\cdots\end{bmatrix} \rightarrow \cdots \rightarrow\begin{bmatrix}h_\Theta(x)_1 \newline h_\Theta(x)_2 \newline h_\Theta(x)_3 \newline h_\Theta(x)_4 \newline\end{bmatrix} \rightarrow\end{align*}\]</span><p>We can define our set of resulting classes as y:<p><img src=Neural-Networks\multi_neur_res.png alt=Neur_multi_res><p>Our final value of our hypothesis for a set of inputs will be one of the elements in y.</div><div><div class=sharethis-inline-share-buttons></div></div></div></section><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(n,t,i,r,u,f,e){n.GoogleAnalyticsObject=u;n[u]=n[u]||function(){(n[u].q=n[u].q||[]).push(arguments)};n[u].l=1*new Date;f=t.createElement(i);e=t.getElementsByTagName(i)[0];f.async=1;f.src=r;e.parentNode.insertBefore(f,e)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga");ga("create","UA-87583712-1","auto");ga("send","pageview")</script><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5906f3ca75e4e1001109c19a&product=inline-share-buttons"></script>