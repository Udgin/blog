<html>

<head>
    <title>Machine-Learning-Init.-Linear-Regression.-Gradient-Descent</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-exp.min.css">
    <link rel="stylesheet" href="https://unpkg.com/spectre.css/dist/spectre-icons.min.css">
    
    <style>
        .columns .column {
            padding: .4rem;
        }
        #sidebar-id {
            padding: .4rem;
        }
        code {
            padding: 0;
            overflow-x: scroll;
        }
        img {
            max-width: 100%;
        }
        .off-canvas .off-canvas-sidebar
        {
            background: none;
        }
    </style>
</head>

<body>
    <div class="off-canvas off-canvas-sidebar-show">
        <a class="off-canvas-toggle btn btn-primary btn-action" href="#sidebar-id">
            <i class="icon icon-menu"></i>
        </a>
        <div id="sidebar-id" class="off-canvas-sidebar">
            <ul class="menu">
                <li class="menu-item">
                    <div class="tile tile-centered">
                        <div class="tile-icon"><img class="avatar" src="https://media.licdn.com/dms/image/C4E03AQEtgQbQGiCpUQ/profile-displayphoto-shrink_200_200/0?e=1547683200&v=beta&t=YKT1NVMDvlzVocWQtSP2Y6Z4Eoy-fqPLncAIk45nF2U"
                                alt="Avatar"></div>
                        <div class="tile-content">Yauhen Pyl</div>
                    </div>
                </li>
                <li class="divider" data-content="LINKS">
                </li>
                <li class="menu-item">
                    <a href="https://plus.google.com/+UdginPyl">Google+</a>
                </li>
                <li class="menu-item">
                    <a href="https://www.facebook.com/yauhen.pyl">Facebook</a>
                </li>
                <li class="menu-item">
                    <a href="https://pl.linkedin.com/in/eugenepyl">LinkedIn</a>
                </li>
                <li class="menu-item">
                    <a href="https://github.com/eapyl">GitHub</a>
                </li>
                <li class="menu-item">
                    <a href="mailto:gromkaktus@gmail.com">Email</a>
                </li>
            </ul>
        </div>
        <a class="off-canvas-overlay" href="#close"></a>
        <div class="off-canvas-content">
            <div class="container grid-lg">
                <h1 id="machine-learning-init.linear-regression.gradient-descent">Machine Learning Init. Linear Regression. Gradient Descent</h1>
<p>The information is from this <a href="https://www.coursera.org/learn/machine-learning/">course</a>.</p>
<p><a href="https://en.wikipedia.org/wiki/Machine_learning">Machine learning</a> is the subfield of computer science that &quot;gives computers the ability to learn without being explicitly programmed&quot; (Arthur Samuel, 1959).</p>
<p>In general, any machine learning problem can be assigned to one of two broad classifications:</p>
<ul>
<li>supervised learning (&quot;regression&quot; and &quot;classification&quot;)</li>
<li>unsupervised learning</li>
</ul>
<p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.</p>
<p>Unsupervised learning, on the other hand, allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.</p>
<h3 id="linear-regression-with-one-variable"><a href="https://en.wikipedia.org/wiki/Linear_regression">Linear Regression</a> with One Variable</h3>
<p>In statistics, linear regression is an approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/438px-Linear_regression.svg.png" alt="Linear regression" /></p>
<p>Hypothesis function has the general form:
<span class="math">\[\hat{y} = h_\theta(x) = \theta_0 + \theta_1 x\]</span></p>
<h3 id="cost-function">Cost Function</h3>
<p>We can measure the accuracy of our hypothesis function by using a cost function. This takes an average (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's compared to the actual output y's.</p>
<p><span class="math">\[J(\theta_0, \theta_1) = \dfrac {1}{2m} \displaystyle \sum _{i=1}^m \left ( \hat{y}_{i}- y_{i} \right)^2  = \dfrac {1}{2m} \displaystyle \sum _{i=1}^m \left (h_\theta (x_{i}) - y_{i} \right)^2\]</span></p>
<p>If we try to think of it in visual terms, our training data set is scattered on the x-y plane. We are trying to make straight line (defined by <span class="math">\(h_\theta(x)\)</span>) which passes through this scattered set of data. Our objective is to get the best possible line. The best possible line will be such so that the average squared vertical distances of the scattered points from the line will be the least. In the best case, the line should pass through all the points of our training data set. In such a case the value of <span class="math">\(J(\theta_0, (\theta_1\)</span>) will be 0.</p>
<h3 id="gradient-descent">Gradient Descent</h3>
<p>There is hypothesis function and there are a set of {x, y} values, so we need to find <span class="math">\(\theta_0\)</span> and <span class="math">\(\theta_1\)</span>.</p>
<p>The gradient descent algorithm is:</p>
<p><span class="math">\[\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)\]</span></p>
<h3 id="gradient-descent-for-linear-regression">Gradient Descent for Linear Regression</h3>
<p><span class="math">\[\begin{align*} \text{repeat until convergence: } \lbrace &amp; \newline \theta_0 := &amp; \theta_0 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m}(h_\theta(x_{i}) - y_{i}) \newline \theta_1 := &amp; \theta_1 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m}\left((h_\theta(x_{i}) - y_{i}) x_{i}\right) \newline \rbrace&amp; \end{align*}\]</span></p>

                <div class="sharethis-inline-share-buttons"></div>
                <div id="disqus_thread"></div>
                <script>
                    (function() { // DON'T EDIT BELOW THIS LINE
                        var d = document,
                            s = d.createElement('script');
                        s.src = '//eapyl-github-io.disqus.com/embed.js';
                        s.setAttribute('data-timestamp', +new Date());
                        (d.head || d.body).appendChild(s);
                    })();
                </script>
            </div>
        </div>
    </div>
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    
        ga('create', 'UA-87583712-1', 'auto');
        ga('send', 'pageview');
    </script>
    <script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5906f3ca75e4e1001109c19a&product=inline-share-buttons"></script>
</body>

</html>