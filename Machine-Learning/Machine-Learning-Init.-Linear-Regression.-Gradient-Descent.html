<title>Machine Learning Init. Linear Regression. Gradient Descent</title><meta name=viewport content="width=device-width, initial-scale=1.0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.4/css/bulma.min.css><style>.content .tag,.content .number{display:inline;padding:inherit;font-size:inherit;line-height:inherit;text-align:inherit;vertical-align:inherit;border-radius:inherit;font-weight:inherit;white-space:inherit;background:inherit;margin:inherit}</style><nav class=navbar role=navigation aria-label="main navigation"><div class=navbar-brand><a class=navbar-item href=..\..\blog/index.html><img src=..\..\blog/favicon.ico width=28 height=28>Â Programming notes</a> <a role=button class="navbar-burger burger" aria-label=menu aria-expanded=false data-target=navbarBasicExample><span aria-hidden></span> <span aria-hidden></span> <span aria-hidden></span></a></div><div id=navbarBasicExample class=navbar-menu><div class=navbar-start><div class=navbar-item><div class="navbar-item has-dropdown is-hoverable"><a class=navbar-link>About me</a><div class=navbar-dropdown> <a class=navbar-item>Facebook</a> <a class=navbar-item>LinkedIn</a> <a class=navbar-item>GitHub</a> <a class=navbar-item>Email</a></div></div></div></div></div></nav><section class=section><div class=container><div class=content><h1 id=machine-learning-init.linear-regression.gradient-descent>Machine Learning Init. Linear Regression. Gradient Descent</h1><p>The information is from this <a href=https://www.coursera.org/learn/machine-learning/ >course</a>.<p><a href=https://en.wikipedia.org/wiki/Machine_learning>Machine learning</a> is the subfield of computer science that "gives computers the ability to learn without being explicitly programmed" (Arthur Samuel, 1959).<p>In general, any machine learning problem can be assigned to one of two broad classifications:<ul><li>supervised learning ("regression" and "classification")<li>unsupervised learning</ul><p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.<p>Unsupervised learning, on the other hand, allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.<h3 id=linear-regression-with-one-variable><a href=https://en.wikipedia.org/wiki/Linear_regression>Linear Regression</a> with One Variable</h3><p>In statistics, linear regression is an approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression.<p><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/438px-Linear_regression.svg.png alt="Linear regression"><p>Hypothesis function has the general form: <span class=math>\[\hat{y} = h_\theta(x) = \theta_0 + \theta_1 x\]</span><h3 id=cost-function>Cost Function</h3><p>We can measure the accuracy of our hypothesis function by using a cost function. This takes an average (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's compared to the actual output y's.<p><span class=math>\[J(\theta_0, \theta_1) = \dfrac {1}{2m} \displaystyle \sum _{i=1}^m \left ( \hat{y}_{i}- y_{i} \right)^2 = \dfrac {1}{2m} \displaystyle \sum _{i=1}^m \left (h_\theta (x_{i}) - y_{i} \right)^2\]</span><p>If we try to think of it in visual terms, our training data set is scattered on the x-y plane. We are trying to make straight line (defined by <span class=math>\(h_\theta(x)\)</span>) which passes through this scattered set of data. Our objective is to get the best possible line. The best possible line will be such so that the average squared vertical distances of the scattered points from the line will be the least. In the best case, the line should pass through all the points of our training data set. In such a case the value of <span class=math>\(J(\theta_0, (\theta_1\)</span>) will be 0.<h3 id=gradient-descent>Gradient Descent</h3><p>There is hypothesis function and there are a set of {x, y} values, so we need to find <span class=math>\(\theta_0\)</span> and <span class=math>\(\theta_1\)</span>.<p>The gradient descent algorithm is:<p><span class=math>\[\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)\]</span><h3 id=gradient-descent-for-linear-regression>Gradient Descent for Linear Regression</h3><p><span class=math>\[\begin{align*} \text{repeat until convergence: } \lbrace &amp; \newline \theta_0 := &amp; \theta_0 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m}(h_\theta(x_{i}) - y_{i}) \newline \theta_1 := &amp; \theta_1 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m}\left((h_\theta(x_{i}) - y_{i}) x_{i}\right) \newline \rbrace&amp; \end{align*}\]</span></div><div><div class=sharethis-inline-share-buttons></div></div></div></section><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(n,t,i,r,u,f,e){n.GoogleAnalyticsObject=u;n[u]=n[u]||function(){(n[u].q=n[u].q||[]).push(arguments)};n[u].l=1*new Date;f=t.createElement(i);e=t.getElementsByTagName(i)[0];f.async=1;f.src=r;e.parentNode.insertBefore(f,e)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga");ga("create","UA-87583712-1","auto");ga("send","pageview")</script><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5906f3ca75e4e1001109c19a&product=inline-share-buttons"></script>